{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "colab_workshop_adversarial_debiasing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephineHonore/AIF360/blob/master/colab_examples/colab_workshop_adversarial_debiasing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_NepKWve3LD",
        "colab_type": "text"
      },
      "source": [
        "# Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3IYz9Vcd46z",
        "colab_type": "text"
      },
      "source": [
        "This section configures your environment to be able to run this notebook on Google Colab. Before you run this notebook, make sure you are running in a python 3 environment. You can change your runtime environment by choosing \n",
        "> Runtime > Change runtime type\n",
        "\n",
        "in the menu.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5R8DDwIeDyz",
        "colab_type": "code",
        "outputId": "6c655222-682c-45ec-ae44-d52042640624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyUy_rRXfNLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This notebook runs in Tensorflow 1.x. Soon will default be 2.x in Colab.\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QCw5PcVdE7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "654b9e53-ee6c-4da5-c45e-df7ca352735c"
      },
      "source": [
        "!pip install -q -U \\\n",
        "  aif360==0.2.2 \\\n",
        "  tqdm==4.38.0 \\\n",
        "  tensorflow==1.15 \\\n",
        "  numpy==1.17.4 \\\n",
        "  matplotlib==3.1.1 \\\n",
        "  pandas==0.25.3 \\\n",
        "  scipy==1.3.2 \\\n",
        "  scikit-learn==0.21.3 \\\n",
        "  cvxpy==1.0.25 \\\n",
        "  scs==2.1.0 \\\n",
        "  numba==0.42.0 \\\n",
        "  networkx==2.4  \\\n",
        "  imgaug==0.2.6 \\\n",
        "  BlackBoxAuditing==0.1.54 \\\n",
        "  lime==0.1.1.36 \\\n",
        "  adversarial-robustness-toolbox==1.0.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 56.4MB 42kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 63.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 634kB 59.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 48.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 52.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 378kB 59.7MB/s \n",
            "\u001b[?25h  Building wheel for scs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R6WMg5zJ0Yt",
        "colab_type": "text"
      },
      "source": [
        "## Notes\n",
        "- The above pip command is created using AIF360's [requirements.txt](https://github.com/josephineHonore/AIF360/blob/master/requirements.txt). At the moment, the job to update these libraries is manual.\n",
        "- The original notebook uses Markdown to display formated text. Currently this is [unsupported](https://github.com/googlecolab/colabtools/issues/322) in Colab.\n",
        "- The tensorflow dependency is not needed for all other notebooks.\n",
        "- We have changed TensorFlow's logging level to `ERROR`, just after the import of the library, to limit the amount of logging shown to the user.\n",
        "- We have added code to fix the random seeds for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g_a1N5zW23l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printb(text):\n",
        "  \"\"\"Auxiliar function to print in bold.\n",
        "    Compensates for bug in Colab that doesn't show Markdown(diplay('text'))\n",
        "  \"\"\"\n",
        "  print('\\x1b[1;30m'+text+'\\x1b[0m')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQZm1kvfevkw",
        "colab_type": "text"
      },
      "source": [
        "# Start of Original Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI9JjWykdBgu",
        "colab_type": "text"
      },
      "source": [
        "#### This notebook demonstrates the use of adversarial debiasing algorithm to learn a fair classifier.\n",
        "Adversarial debiasing [1] is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary's ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit. We will see how to use this algorithm for learning models with and without fairness constraints and apply them on the Adult dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8X6I3szdBgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "# Load all necessary packages\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
        "\n",
        "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APNd5vJvXM9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
        "SEED = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcapCQdodBg8",
        "colab_type": "text"
      },
      "source": [
        "#### Load dataset and set options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8GyuuH-dBg_",
        "colab_type": "code",
        "outputId": "9fa7e5f1-2c0d-4299-c4ec-9e6c6f863ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Get the dataset and split into train and test\n",
        "dataset_orig = load_preproc_data_adult()\n",
        "\n",
        "privileged_groups = [{'sex': 1}]\n",
        "unprivileged_groups = [{'sex': 0}]\n",
        "\n",
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True, seed=SEED)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/aif360/datasets/standard_dataset.py:142: FutureWarning: outer method for ufunc <ufunc 'equal'> is not implemented on pandas objects. Returning an ndarray, but in the future this will raise a 'NotImplementedError'. Consider explicitly converting the Series to an array with '.array' first.\n",
            "  df[label_name]))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aePh7ARSdBhI",
        "colab_type": "code",
        "outputId": "b6be103d-fd24-4552-95d6-efc7fb6e6e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# print out some labels, names, etc.\n",
        "#display(Markdown(\"#### Training Dataset shape\"))\n",
        "printb('#### Training Dataset shape')\n",
        "print(dataset_orig_train.features.shape)\n",
        "#display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
        "printb(\"#### Favorable and unfavorable labels\")\n",
        "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
        "#display(Markdown(\"#### Protected attribute names\"))\n",
        "printb(\"#### Protected attribute names\")\n",
        "print(dataset_orig_train.protected_attribute_names)\n",
        "#display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
        "printb(\"#### Privileged and unprivileged protected attribute values\")\n",
        "print(dataset_orig_train.privileged_protected_attributes, \n",
        "      dataset_orig_train.unprivileged_protected_attributes)\n",
        "#display(Markdown(\"#### Dataset feature names\"))\n",
        "printb(\"#### Dataset feature names\")\n",
        "print(dataset_orig_train.feature_names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30m#### Training Dataset shape\u001b[0m\n",
            "(34189, 18)\n",
            "\u001b[1;30m#### Favorable and unfavorable labels\u001b[0m\n",
            "1.0 0.0\n",
            "\u001b[1;30m#### Protected attribute names\u001b[0m\n",
            "['sex', 'race']\n",
            "\u001b[1;30m#### Privileged and unprivileged protected attribute values\u001b[0m\n",
            "[array([1.]), array([1.])] [array([0.]), array([0.])]\n",
            "\u001b[1;30m#### Dataset feature names\u001b[0m\n",
            "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D_FiXzGdBhQ",
        "colab_type": "text"
      },
      "source": [
        "#### Metric for original training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEjeW5bIdBhS",
        "colab_type": "code",
        "outputId": "223d5795-0377-4bc3-d00b-adaf210ce07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Metric for the original dataset\n",
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "#display(Markdown(\"#### Original training dataset\"))\n",
        "printb(\"#### Original training dataset\")\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
        "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30m#### Original training dataset\u001b[0m\n",
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.195979\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.191102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RGDBY2RdBhZ",
        "colab_type": "code",
        "outputId": "45579c28-41d7-4095-a5e9-9d1602134685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "min_max_scaler = MaxAbsScaler()\n",
        "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
        "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
        "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "#display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
        "printb(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\")\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
        "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
        "                             unprivileged_groups=unprivileged_groups,\n",
        "                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30m#### Scaled dataset - Verify that the scaling does not affect the group label statistics\u001b[0m\n",
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.195979\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.191102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Yli0jndBhh",
        "colab_type": "text"
      },
      "source": [
        "### Learn plan classifier without debiasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlAILO8edBhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load post-processing algorithm that equalizes the odds\n",
        "# Learn parameters with debias set to False\n",
        "sess = tf.Session()\n",
        "tf.set_random_seed(SEED)\n",
        "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='plain_classifier',\n",
        "                          debias=False,\n",
        "                          sess=sess,\n",
        "                          seed=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kDacKLdtdBhr",
        "colab_type": "code",
        "outputId": "35bcdf86-fe2c-411c-f30e-9749b281b79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "plain_model.fit(dataset_orig_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.737970\n",
            "epoch 0; iter: 200; batch classifier loss: 0.438434\n",
            "epoch 1; iter: 0; batch classifier loss: 0.376381\n",
            "epoch 1; iter: 200; batch classifier loss: 0.418228\n",
            "epoch 2; iter: 0; batch classifier loss: 0.385003\n",
            "epoch 2; iter: 200; batch classifier loss: 0.609906\n",
            "epoch 3; iter: 0; batch classifier loss: 0.352963\n",
            "epoch 3; iter: 200; batch classifier loss: 0.464395\n",
            "epoch 4; iter: 0; batch classifier loss: 0.438074\n",
            "epoch 4; iter: 200; batch classifier loss: 0.466126\n",
            "epoch 5; iter: 0; batch classifier loss: 0.423859\n",
            "epoch 5; iter: 200; batch classifier loss: 0.453185\n",
            "epoch 6; iter: 0; batch classifier loss: 0.415533\n",
            "epoch 6; iter: 200; batch classifier loss: 0.472421\n",
            "epoch 7; iter: 0; batch classifier loss: 0.499586\n",
            "epoch 7; iter: 200; batch classifier loss: 0.404337\n",
            "epoch 8; iter: 0; batch classifier loss: 0.476573\n",
            "epoch 8; iter: 200; batch classifier loss: 0.430814\n",
            "epoch 9; iter: 0; batch classifier loss: 0.383572\n",
            "epoch 9; iter: 200; batch classifier loss: 0.442796\n",
            "epoch 10; iter: 0; batch classifier loss: 0.418980\n",
            "epoch 10; iter: 200; batch classifier loss: 0.365441\n",
            "epoch 11; iter: 0; batch classifier loss: 0.374628\n",
            "epoch 11; iter: 200; batch classifier loss: 0.340155\n",
            "epoch 12; iter: 0; batch classifier loss: 0.471620\n",
            "epoch 12; iter: 200; batch classifier loss: 0.461761\n",
            "epoch 13; iter: 0; batch classifier loss: 0.411449\n",
            "epoch 13; iter: 200; batch classifier loss: 0.382767\n",
            "epoch 14; iter: 0; batch classifier loss: 0.501918\n",
            "epoch 14; iter: 200; batch classifier loss: 0.399592\n",
            "epoch 15; iter: 0; batch classifier loss: 0.492031\n",
            "epoch 15; iter: 200; batch classifier loss: 0.420387\n",
            "epoch 16; iter: 0; batch classifier loss: 0.337869\n",
            "epoch 16; iter: 200; batch classifier loss: 0.327117\n",
            "epoch 17; iter: 0; batch classifier loss: 0.382844\n",
            "epoch 17; iter: 200; batch classifier loss: 0.393359\n",
            "epoch 18; iter: 0; batch classifier loss: 0.466848\n",
            "epoch 18; iter: 200; batch classifier loss: 0.451325\n",
            "epoch 19; iter: 0; batch classifier loss: 0.471593\n",
            "epoch 19; iter: 200; batch classifier loss: 0.489679\n",
            "epoch 20; iter: 0; batch classifier loss: 0.435129\n",
            "epoch 20; iter: 200; batch classifier loss: 0.399314\n",
            "epoch 21; iter: 0; batch classifier loss: 0.468515\n",
            "epoch 21; iter: 200; batch classifier loss: 0.387481\n",
            "epoch 22; iter: 0; batch classifier loss: 0.440697\n",
            "epoch 22; iter: 200; batch classifier loss: 0.396086\n",
            "epoch 23; iter: 0; batch classifier loss: 0.517421\n",
            "epoch 23; iter: 200; batch classifier loss: 0.377211\n",
            "epoch 24; iter: 0; batch classifier loss: 0.454874\n",
            "epoch 24; iter: 200; batch classifier loss: 0.428849\n",
            "epoch 25; iter: 0; batch classifier loss: 0.350650\n",
            "epoch 25; iter: 200; batch classifier loss: 0.359391\n",
            "epoch 26; iter: 0; batch classifier loss: 0.444993\n",
            "epoch 26; iter: 200; batch classifier loss: 0.509191\n",
            "epoch 27; iter: 0; batch classifier loss: 0.434238\n",
            "epoch 27; iter: 200; batch classifier loss: 0.440882\n",
            "epoch 28; iter: 0; batch classifier loss: 0.473466\n",
            "epoch 28; iter: 200; batch classifier loss: 0.437810\n",
            "epoch 29; iter: 0; batch classifier loss: 0.405944\n",
            "epoch 29; iter: 200; batch classifier loss: 0.455823\n",
            "epoch 30; iter: 0; batch classifier loss: 0.436632\n",
            "epoch 30; iter: 200; batch classifier loss: 0.305855\n",
            "epoch 31; iter: 0; batch classifier loss: 0.411257\n",
            "epoch 31; iter: 200; batch classifier loss: 0.400233\n",
            "epoch 32; iter: 0; batch classifier loss: 0.445646\n",
            "epoch 32; iter: 200; batch classifier loss: 0.392651\n",
            "epoch 33; iter: 0; batch classifier loss: 0.535372\n",
            "epoch 33; iter: 200; batch classifier loss: 0.368077\n",
            "epoch 34; iter: 0; batch classifier loss: 0.380503\n",
            "epoch 34; iter: 200; batch classifier loss: 0.352562\n",
            "epoch 35; iter: 0; batch classifier loss: 0.414897\n",
            "epoch 35; iter: 200; batch classifier loss: 0.397666\n",
            "epoch 36; iter: 0; batch classifier loss: 0.426086\n",
            "epoch 36; iter: 200; batch classifier loss: 0.403394\n",
            "epoch 37; iter: 0; batch classifier loss: 0.388096\n",
            "epoch 37; iter: 200; batch classifier loss: 0.470584\n",
            "epoch 38; iter: 0; batch classifier loss: 0.364712\n",
            "epoch 38; iter: 200; batch classifier loss: 0.438600\n",
            "epoch 39; iter: 0; batch classifier loss: 0.424411\n",
            "epoch 39; iter: 200; batch classifier loss: 0.440139\n",
            "epoch 40; iter: 0; batch classifier loss: 0.421317\n",
            "epoch 40; iter: 200; batch classifier loss: 0.416627\n",
            "epoch 41; iter: 0; batch classifier loss: 0.470356\n",
            "epoch 41; iter: 200; batch classifier loss: 0.441019\n",
            "epoch 42; iter: 0; batch classifier loss: 0.399550\n",
            "epoch 42; iter: 200; batch classifier loss: 0.428594\n",
            "epoch 43; iter: 0; batch classifier loss: 0.531945\n",
            "epoch 43; iter: 200; batch classifier loss: 0.445028\n",
            "epoch 44; iter: 0; batch classifier loss: 0.407228\n",
            "epoch 44; iter: 200; batch classifier loss: 0.482855\n",
            "epoch 45; iter: 0; batch classifier loss: 0.513576\n",
            "epoch 45; iter: 200; batch classifier loss: 0.419939\n",
            "epoch 46; iter: 0; batch classifier loss: 0.512533\n",
            "epoch 46; iter: 200; batch classifier loss: 0.482076\n",
            "epoch 47; iter: 0; batch classifier loss: 0.435361\n",
            "epoch 47; iter: 200; batch classifier loss: 0.331843\n",
            "epoch 48; iter: 0; batch classifier loss: 0.426704\n",
            "epoch 48; iter: 200; batch classifier loss: 0.450011\n",
            "epoch 49; iter: 0; batch classifier loss: 0.454564\n",
            "epoch 49; iter: 200; batch classifier loss: 0.399660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f8f5e0e7630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1x0uGG4dBhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
        "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLKA0ALndBh3",
        "colab_type": "code",
        "outputId": "3551e839-c07a-46a1-8bdb-bd40d05e9086",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "#display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "printb(\"#### Plain model - without debiasing - dataset metrics\")\n",
        "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "#display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "printb(\"#### Plain model - without debiasing - classification metrics\")\n",
        "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_nodebiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30m#### Plain model - without debiasing - dataset metrics\u001b[0m\n",
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.230944\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.233361\n",
            "\u001b[1;30m#### Plain model - without debiasing - classification metrics\u001b[0m\n",
            "Test set: Classification accuracy = 0.801679\n",
            "Test set: Balanced classification accuracy = 0.666963\n",
            "Test set: Disparate impact = 0.000000\n",
            "Test set: Equal opportunity difference = -0.484879\n",
            "Test set: Average odds difference = -0.305113\n",
            "Test set: Theil_index = 0.172990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXaAnczRdBh-",
        "colab_type": "text"
      },
      "source": [
        "### Apply in-processing algorithm based on adversarial learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBI5i5BvdBiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "tf.set_random_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZLhz4WVdBiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learn parameters with debias set to True\n",
        "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
        "                          unprivileged_groups = unprivileged_groups,\n",
        "                          scope_name='debiased_classifier',\n",
        "                          debias=True,\n",
        "                          sess=sess,\n",
        "                          seed=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Qhydrm-PdBiL",
        "colab_type": "code",
        "outputId": "33d1e491-5ffa-4f95-d2c1-f035c69fd35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "debiased_model.fit(dataset_orig_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0; iter: 0; batch classifier loss: 0.737970; batch adversarial loss: 0.666912\n",
            "epoch 0; iter: 200; batch classifier loss: 0.439217; batch adversarial loss: 0.650681\n",
            "epoch 1; iter: 0; batch classifier loss: 0.395579; batch adversarial loss: 0.653747\n",
            "epoch 1; iter: 200; batch classifier loss: 0.398832; batch adversarial loss: 0.632667\n",
            "epoch 2; iter: 0; batch classifier loss: 0.393730; batch adversarial loss: 0.596025\n",
            "epoch 2; iter: 200; batch classifier loss: 0.647770; batch adversarial loss: 0.622425\n",
            "epoch 3; iter: 0; batch classifier loss: 0.387068; batch adversarial loss: 0.639398\n",
            "epoch 3; iter: 200; batch classifier loss: 0.555255; batch adversarial loss: 0.648315\n",
            "epoch 4; iter: 0; batch classifier loss: 0.496626; batch adversarial loss: 0.605289\n",
            "epoch 4; iter: 200; batch classifier loss: 0.536177; batch adversarial loss: 0.627946\n",
            "epoch 5; iter: 0; batch classifier loss: 0.517603; batch adversarial loss: 0.672201\n",
            "epoch 5; iter: 200; batch classifier loss: 0.520227; batch adversarial loss: 0.577357\n",
            "epoch 6; iter: 0; batch classifier loss: 0.420755; batch adversarial loss: 0.689390\n",
            "epoch 6; iter: 200; batch classifier loss: 0.505929; batch adversarial loss: 0.614497\n",
            "epoch 7; iter: 0; batch classifier loss: 0.541964; batch adversarial loss: 0.618190\n",
            "epoch 7; iter: 200; batch classifier loss: 0.422260; batch adversarial loss: 0.620152\n",
            "epoch 8; iter: 0; batch classifier loss: 0.507550; batch adversarial loss: 0.650372\n",
            "epoch 8; iter: 200; batch classifier loss: 0.466851; batch adversarial loss: 0.587887\n",
            "epoch 9; iter: 0; batch classifier loss: 0.408392; batch adversarial loss: 0.622356\n",
            "epoch 9; iter: 200; batch classifier loss: 0.455534; batch adversarial loss: 0.610994\n",
            "epoch 10; iter: 0; batch classifier loss: 0.428361; batch adversarial loss: 0.597438\n",
            "epoch 10; iter: 200; batch classifier loss: 0.378832; batch adversarial loss: 0.582671\n",
            "epoch 11; iter: 0; batch classifier loss: 0.400031; batch adversarial loss: 0.616592\n",
            "epoch 11; iter: 200; batch classifier loss: 0.332745; batch adversarial loss: 0.642008\n",
            "epoch 12; iter: 0; batch classifier loss: 0.497974; batch adversarial loss: 0.629938\n",
            "epoch 12; iter: 200; batch classifier loss: 0.490180; batch adversarial loss: 0.586052\n",
            "epoch 13; iter: 0; batch classifier loss: 0.458903; batch adversarial loss: 0.620164\n",
            "epoch 13; iter: 200; batch classifier loss: 0.383686; batch adversarial loss: 0.576971\n",
            "epoch 14; iter: 0; batch classifier loss: 0.523525; batch adversarial loss: 0.562203\n",
            "epoch 14; iter: 200; batch classifier loss: 0.410522; batch adversarial loss: 0.615920\n",
            "epoch 15; iter: 0; batch classifier loss: 0.485316; batch adversarial loss: 0.624934\n",
            "epoch 15; iter: 200; batch classifier loss: 0.421634; batch adversarial loss: 0.615704\n",
            "epoch 16; iter: 0; batch classifier loss: 0.337426; batch adversarial loss: 0.687306\n",
            "epoch 16; iter: 200; batch classifier loss: 0.347812; batch adversarial loss: 0.576184\n",
            "epoch 17; iter: 0; batch classifier loss: 0.374437; batch adversarial loss: 0.630476\n",
            "epoch 17; iter: 200; batch classifier loss: 0.416071; batch adversarial loss: 0.562459\n",
            "epoch 18; iter: 0; batch classifier loss: 0.481965; batch adversarial loss: 0.583249\n",
            "epoch 18; iter: 200; batch classifier loss: 0.456365; batch adversarial loss: 0.573830\n",
            "epoch 19; iter: 0; batch classifier loss: 0.468688; batch adversarial loss: 0.618509\n",
            "epoch 19; iter: 200; batch classifier loss: 0.481366; batch adversarial loss: 0.549141\n",
            "epoch 20; iter: 0; batch classifier loss: 0.433151; batch adversarial loss: 0.679923\n",
            "epoch 20; iter: 200; batch classifier loss: 0.423800; batch adversarial loss: 0.567315\n",
            "epoch 21; iter: 0; batch classifier loss: 0.468362; batch adversarial loss: 0.684850\n",
            "epoch 21; iter: 200; batch classifier loss: 0.436339; batch adversarial loss: 0.588229\n",
            "epoch 22; iter: 0; batch classifier loss: 0.442108; batch adversarial loss: 0.593895\n",
            "epoch 22; iter: 200; batch classifier loss: 0.419877; batch adversarial loss: 0.588531\n",
            "epoch 23; iter: 0; batch classifier loss: 0.497069; batch adversarial loss: 0.573661\n",
            "epoch 23; iter: 200; batch classifier loss: 0.394757; batch adversarial loss: 0.608492\n",
            "epoch 24; iter: 0; batch classifier loss: 0.479913; batch adversarial loss: 0.628213\n",
            "epoch 24; iter: 200; batch classifier loss: 0.458658; batch adversarial loss: 0.577706\n",
            "epoch 25; iter: 0; batch classifier loss: 0.354308; batch adversarial loss: 0.641665\n",
            "epoch 25; iter: 200; batch classifier loss: 0.346914; batch adversarial loss: 0.647337\n",
            "epoch 26; iter: 0; batch classifier loss: 0.482014; batch adversarial loss: 0.575979\n",
            "epoch 26; iter: 200; batch classifier loss: 0.528614; batch adversarial loss: 0.638195\n",
            "epoch 27; iter: 0; batch classifier loss: 0.432474; batch adversarial loss: 0.618400\n",
            "epoch 27; iter: 200; batch classifier loss: 0.446246; batch adversarial loss: 0.654236\n",
            "epoch 28; iter: 0; batch classifier loss: 0.502022; batch adversarial loss: 0.572449\n",
            "epoch 28; iter: 200; batch classifier loss: 0.422838; batch adversarial loss: 0.577163\n",
            "epoch 29; iter: 0; batch classifier loss: 0.405007; batch adversarial loss: 0.597697\n",
            "epoch 29; iter: 200; batch classifier loss: 0.470918; batch adversarial loss: 0.542366\n",
            "epoch 30; iter: 0; batch classifier loss: 0.457821; batch adversarial loss: 0.523713\n",
            "epoch 30; iter: 200; batch classifier loss: 0.325405; batch adversarial loss: 0.643844\n",
            "epoch 31; iter: 0; batch classifier loss: 0.445640; batch adversarial loss: 0.638554\n",
            "epoch 31; iter: 200; batch classifier loss: 0.415731; batch adversarial loss: 0.625577\n",
            "epoch 32; iter: 0; batch classifier loss: 0.452549; batch adversarial loss: 0.574977\n",
            "epoch 32; iter: 200; batch classifier loss: 0.389529; batch adversarial loss: 0.639905\n",
            "epoch 33; iter: 0; batch classifier loss: 0.530894; batch adversarial loss: 0.601718\n",
            "epoch 33; iter: 200; batch classifier loss: 0.394965; batch adversarial loss: 0.618835\n",
            "epoch 34; iter: 0; batch classifier loss: 0.374573; batch adversarial loss: 0.651385\n",
            "epoch 34; iter: 200; batch classifier loss: 0.365545; batch adversarial loss: 0.637595\n",
            "epoch 35; iter: 0; batch classifier loss: 0.423135; batch adversarial loss: 0.671528\n",
            "epoch 35; iter: 200; batch classifier loss: 0.422194; batch adversarial loss: 0.643425\n",
            "epoch 36; iter: 0; batch classifier loss: 0.443166; batch adversarial loss: 0.559023\n",
            "epoch 36; iter: 200; batch classifier loss: 0.432213; batch adversarial loss: 0.612111\n",
            "epoch 37; iter: 0; batch classifier loss: 0.407634; batch adversarial loss: 0.681092\n",
            "epoch 37; iter: 200; batch classifier loss: 0.484741; batch adversarial loss: 0.596587\n",
            "epoch 38; iter: 0; batch classifier loss: 0.383160; batch adversarial loss: 0.644193\n",
            "epoch 38; iter: 200; batch classifier loss: 0.443410; batch adversarial loss: 0.590924\n",
            "epoch 39; iter: 0; batch classifier loss: 0.465071; batch adversarial loss: 0.553392\n",
            "epoch 39; iter: 200; batch classifier loss: 0.466281; batch adversarial loss: 0.644508\n",
            "epoch 40; iter: 0; batch classifier loss: 0.429797; batch adversarial loss: 0.679400\n",
            "epoch 40; iter: 200; batch classifier loss: 0.456626; batch adversarial loss: 0.574034\n",
            "epoch 41; iter: 0; batch classifier loss: 0.494414; batch adversarial loss: 0.547577\n",
            "epoch 41; iter: 200; batch classifier loss: 0.443492; batch adversarial loss: 0.629917\n",
            "epoch 42; iter: 0; batch classifier loss: 0.401878; batch adversarial loss: 0.605614\n",
            "epoch 42; iter: 200; batch classifier loss: 0.452918; batch adversarial loss: 0.557213\n",
            "epoch 43; iter: 0; batch classifier loss: 0.552057; batch adversarial loss: 0.574666\n",
            "epoch 43; iter: 200; batch classifier loss: 0.463933; batch adversarial loss: 0.614764\n",
            "epoch 44; iter: 0; batch classifier loss: 0.417417; batch adversarial loss: 0.630106\n",
            "epoch 44; iter: 200; batch classifier loss: 0.481081; batch adversarial loss: 0.645082\n",
            "epoch 45; iter: 0; batch classifier loss: 0.523523; batch adversarial loss: 0.545741\n",
            "epoch 45; iter: 200; batch classifier loss: 0.430259; batch adversarial loss: 0.608178\n",
            "epoch 46; iter: 0; batch classifier loss: 0.513441; batch adversarial loss: 0.653369\n",
            "epoch 46; iter: 200; batch classifier loss: 0.491423; batch adversarial loss: 0.576256\n",
            "epoch 47; iter: 0; batch classifier loss: 0.444084; batch adversarial loss: 0.604843\n",
            "epoch 47; iter: 200; batch classifier loss: 0.343025; batch adversarial loss: 0.650595\n",
            "epoch 48; iter: 0; batch classifier loss: 0.448364; batch adversarial loss: 0.565534\n",
            "epoch 48; iter: 200; batch classifier loss: 0.439480; batch adversarial loss: 0.643655\n",
            "epoch 49; iter: 0; batch classifier loss: 0.462607; batch adversarial loss: 0.571387\n",
            "epoch 49; iter: 200; batch classifier loss: 0.414166; batch adversarial loss: 0.563098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f8f52f1f860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSL33flZdBiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the plain model to test data\n",
        "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
        "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3izs52oMdBia",
        "colab_type": "code",
        "outputId": "52506a96-39e3-4c48-e888-91eaa9053494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Metrics for the dataset from plain model (without debiasing)\n",
        "#display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
        "printb(\"#### Plain model - without debiasing - dataset metrics\")\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
        "\n",
        "# Metrics for the dataset from model with debiasing\n",
        "#display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
        "printb(\"#### Model - with debiasing - dataset metrics\")\n",
        "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
        "\n",
        "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
        "\n",
        "\n",
        "\n",
        "#display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
        "printb(\"#### Plain model - without debiasing - classification metrics\")\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
        "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
        "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
        "\n",
        "\n",
        "\n",
        "#display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
        "printb(\"#### Model - with debiasing - classification metrics\")\n",
        "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
        "                                                 dataset_debiasing_test,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
        "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
        "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
        "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
        "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
        "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30m#### Plain model - without debiasing - dataset metrics\u001b[0m\n",
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.230944\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.233361\n",
            "\u001b[1;30m#### Model - with debiasing - dataset metrics\u001b[0m\n",
            "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.087395\n",
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.086066\n",
            "\u001b[1;30m#### Plain model - without debiasing - classification metrics\u001b[0m\n",
            "Test set: Classification accuracy = 0.801679\n",
            "Test set: Balanced classification accuracy = 0.666963\n",
            "Test set: Disparate impact = 0.000000\n",
            "Test set: Equal opportunity difference = -0.484879\n",
            "Test set: Average odds difference = -0.305113\n",
            "Test set: Theil_index = 0.172990\n",
            "\u001b[1;30m#### Model - with debiasing - classification metrics\u001b[0m\n",
            "Test set: Classification accuracy = 0.790555\n",
            "Test set: Balanced classification accuracy = 0.667707\n",
            "Test set: Disparate impact = 0.583651\n",
            "Test set: Equal opportunity difference = -0.056681\n",
            "Test set: Average odds difference = -0.036982\n",
            "Test set: Theil_index = 0.171585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE04h_pXdBik",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "    References:\n",
        "    [1] B. H. Zhang, B. Lemoine, and M. Mitchell, \"Mitigating UnwantedBiases with Adversarial Learning,\" \n",
        "    AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHgmAjjLEZuB",
        "colab_type": "text"
      },
      "source": [
        "# Exploring the results\n",
        "\n",
        "Let's take a deeper look at the previous results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54j99wHteilZ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Code to define `print_table` function to show results in tabular format\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def print_table(headers,data,caption=\"\"):\n",
        "  \"\"\"\n",
        "  Prints a table given headers and data\n",
        "\n",
        "  Inputs:\n",
        "    - headers: a list of N headers\n",
        "    - data: a list of N-element lists containing the data to display\n",
        "    - caption: a string describing the data\n",
        "\n",
        "  Outputs:\n",
        "    - A HTML display of the table\n",
        "\n",
        "  Example:\n",
        "    caption = \"A caption\"\n",
        "    headers = [\"row\",\"title 1\", \"title 2\"]\n",
        "    data = [[\"first row\", 1, 2], [\"second row\", 2, 3]]\n",
        "\n",
        "    print_table(headers,data,caption)\n",
        "    \n",
        "\n",
        "         A Caption\n",
        "    -----------------------------------\n",
        "    | row         | title 1 | title 2 |\n",
        "    -----------------------------------\n",
        "    | first row   | 1       | 2       |\n",
        "    -----------------------------------\n",
        "    | second row  | 2       | 3       |\n",
        "    -----------------------------------\n",
        "  \"\"\"\n",
        "  display(HTML(\n",
        "    '<table border=\"1\"><caption>{0}</caption><tr>{1}</tr><tr>{2}</tr></table>'.format(\n",
        "        caption,\n",
        "        '<th>{}</th>'.format('</th><th>'.join(line for line in headers)),\n",
        "        '</tr><tr>'.join(\n",
        "            '<td>{}</td>'.format(\n",
        "                '</td><td>'.join(\n",
        "                    str(_) for _ in row)) for row in data))\n",
        "  ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EAi-ReJ0s4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "33875e3a-f780-432c-d9c6-f3842e155ccc"
      },
      "source": [
        "table = [[\"Train set\",metric_dataset_nodebiasing_train.mean_difference(),metric_dataset_debiasing_train.mean_difference()],\n",
        "         [\"Test set\",metric_dataset_nodebiasing_test.mean_difference(),metric_dataset_debiasing_test.mean_difference()]]\n",
        "headers = ['Statistical parity difference','Without debiasing','With debiasing']\n",
        "caption = \"Difference in mean outcomes between unprivileged and privileged groups\"\n",
        "\n",
        "print_table(headers,table,caption)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\"><caption>Difference in mean outcomes between unprivileged and privileged groups</caption><tr><th>Statistical parity difference</th><th>Without debiasing</th><th>With debiasing</th></tr><tr><td>Train set</td><td>-0.23094425483503983</td><td>-0.08739516361488235</td></tr><tr><td>Test set</td><td>-0.2333605553287056</td><td>-0.08606641998730033</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXnjQvpJFPPD",
        "colab_type": "text"
      },
      "source": [
        "We observe a big reduction in the statistical parity difference by training with Adversarial learning debias mitigation. \n",
        "\n",
        "Let's look at the result of this technique by evaluating other fairness metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kphsnDT6v9F7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "6908c006-7583-4624-bbbd-3b318d4e230b"
      },
      "source": [
        "metrics_final = [[\"Accuracy\", \"%f\" % classified_metric_nodebiasing_test.accuracy(), \"%f\" % classified_metric_debiasing_test.accuracy()],\n",
        "                [\"Balanced classification accuracy\",\"%f\" % bal_acc_nodebiasing_test, \"%f\" % bal_acc_debiasing_test],\n",
        "                [\"Disparate impact\",\"%f\" % classified_metric_nodebiasing_test.disparate_impact(), \"%f\" % classified_metric_debiasing_test.disparate_impact()],\n",
        "                [\"Equal opportunity difference\", \"%f\" % classified_metric_nodebiasing_test.equal_opportunity_difference(), \"%f\" % classified_metric_debiasing_test.equal_opportunity_difference()],\n",
        "                [\"Average odds difference\", \"%f\" % classified_metric_nodebiasing_test.average_odds_difference(), \"%f\" % classified_metric_debiasing_test.average_odds_difference()],\n",
        "                [\"Theil_index\", \"%f\" % classified_metric_nodebiasing_test.theil_index(), \"%f\" % classified_metric_debiasing_test.theil_index()]]\n",
        "headers_final = [\"Classification metric\", \"Without debiasing\",\"With debiasing\"]\n",
        "caption_final = \"Difference in model performance by using Adversarial Learning mitigation\"\n",
        "\n",
        "print_table(headers_final, metrics_final, caption_final)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\"><caption>Difference in model performance by using Adversarial Learning mitigation</caption><tr><th>Classification metric</th><th>Without debiasing</th><th>With debiasing</th></tr><tr><td>Accuracy</td><td>0.801679</td><td>0.790555</td></tr><tr><td>Balanced classification accuracy</td><td>0.666963</td><td>0.667707</td></tr><tr><td>Disparate impact</td><td>0.000000</td><td>0.583651</td></tr><tr><td>Equal opportunity difference</td><td>-0.484879</td><td>-0.056681</td></tr><tr><td>Average odds difference</td><td>-0.305113</td><td>-0.036982</td></tr><tr><td>Theil_index</td><td>0.172990</td><td>0.171585</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXSfLelFS2oz",
        "colab_type": "text"
      },
      "source": [
        "It is hard to remember the definition and the ideal expected value for each metric. We can use [explainers](https://aif360.readthedocs.io/en/latest/modules/explainers.html#) to explain each metric. There are two kind of flavours: TEXT and JSON. The JSON explainers provide structured explanations that can be used to present information to the users. Here are some examples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpjQceTVEUd4",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Define `format_json` function for pretty print of JSON explainers\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n",
        "def format_json(json_str):\n",
        "    return json.dumps(json.loads(json_str, object_pairs_hook=OrderedDict), indent=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGqwaTnO6QwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from aif360.explainers import MetricJSONExplainer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-7kJThIUtdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define explainers for the metrics with and without debiasing\n",
        "ex_nondebias_test = MetricJSONExplainer(classified_metric_nodebiasing_test)\n",
        "ex_debias_test = MetricJSONExplainer(classified_metric_debiasing_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0o1lmC1VCbM",
        "colab_type": "text"
      },
      "source": [
        "Now let's print the explainers for the metrics we used above. Make sure you read the whole text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqUZfgF1EXbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e970dd2e-7fee-4f07-a07b-51b23f460e56"
      },
      "source": [
        "printb(\"Nondebiasing\")\n",
        "print(format_json(ex_nondebias_test.accuracy()))\n",
        "\n",
        "printb(\"Debiasing\")\n",
        "print(format_json(ex_debias_test.accuracy()))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30mNondebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Accuracy\",\n",
            "  \"message\": \"Classification accuracy (ACC): 0.8016788370982052\",\n",
            "  \"numTruePositives\": 1427.0,\n",
            "  \"numTrueNegatives\": 10320.0,\n",
            "  \"numPositives\": 3474.0,\n",
            "  \"numNegatives\": 11179.0,\n",
            "  \"description\": \"Computed as (true positive count + true negative count)/(positive_count + negative_count).\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0\"\n",
            "}\n",
            "\u001b[1;30mDebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Accuracy\",\n",
            "  \"message\": \"Classification accuracy (ACC): 0.7905548351873336\",\n",
            "  \"numTruePositives\": 1508.0,\n",
            "  \"numTrueNegatives\": 10076.0,\n",
            "  \"numPositives\": 3474.0,\n",
            "  \"numNegatives\": 11179.0,\n",
            "  \"description\": \"Computed as (true positive count + true negative count)/(positive_count + negative_count).\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwnbAJbVHqyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "bbc14866-0452-4fee-a056-9fc5d0bfb6e3"
      },
      "source": [
        "printb(\"Nondebiasing\")\n",
        "print(format_json(ex_nondebias_test.disparate_impact()))\n",
        "\n",
        "printb(\"Debiasing\")\n",
        "print(format_json(ex_debias_test.disparate_impact()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30mNondebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Disparate Impact\",\n",
            "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.0\",\n",
            "  \"numPositivePredictionsUnprivileged\": 531.0,\n",
            "  \"numUnprivileged\": 4857.0,\n",
            "  \"numPositivePredictionsPrivileged\": 2943.0,\n",
            "  \"numPrivileged\": 9796.0,\n",
            "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
            "}\n",
            "\u001b[1;30mDebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Disparate Impact\",\n",
            "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.5836510369404474\",\n",
            "  \"numPositivePredictionsUnprivileged\": 531.0,\n",
            "  \"numUnprivileged\": 4857.0,\n",
            "  \"numPositivePredictionsPrivileged\": 2943.0,\n",
            "  \"numPrivileged\": 9796.0,\n",
            "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-wYDDakCW9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "7e4d6ab9-1820-476c-df7d-40080b9fe770"
      },
      "source": [
        "printb(\"Nondebiasing\")\n",
        "print(format_json(ex_nondebias_test.equal_opportunity_difference()))\n",
        "\n",
        "printb(\"Debiasing\")\n",
        "print(format_json(ex_debias_test.equal_opportunity_difference()))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30mNondebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"True Positive Rate Difference\",\n",
            "  \"message\": \"True positive rate difference (true positive rate on unprivileged instances - true positive rate on privileged instances): -0.48487937478763166\",\n",
            "  \"numTruePositivesUnprivileged\": 0.0,\n",
            "  \"numPositivesUnprivileged\": 531.0,\n",
            "  \"numTruePositivesPrivileged\": 1427.0,\n",
            "  \"numPositivesPrivileged\": 2943.0,\n",
            "  \"description\": \"This metric is computed as the difference of true positive rates between the unprivileged and the privileged groups.  The true positive rate is the ratio of true positives to the total number of actual positives for a given group.\",\n",
            "  \"ideal\": \"The ideal value is 0. A value of < 0 implies higher benefit for the privileged group and a value > 0 implies higher benefit for the unprivileged group.\"\n",
            "}\n",
            "\u001b[1;30mDebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"True Positive Rate Difference\",\n",
            "  \"message\": \"True positive rate difference (true positive rate on unprivileged instances - true positive rate on privileged instances): -0.05668146765954263\",\n",
            "  \"numTruePositivesUnprivileged\": 205.0,\n",
            "  \"numPositivesUnprivileged\": 531.0,\n",
            "  \"numTruePositivesPrivileged\": 1303.0,\n",
            "  \"numPositivesPrivileged\": 2943.0,\n",
            "  \"description\": \"This metric is computed as the difference of true positive rates between the unprivileged and the privileged groups.  The true positive rate is the ratio of true positives to the total number of actual positives for a given group.\",\n",
            "  \"ideal\": \"The ideal value is 0. A value of < 0 implies higher benefit for the privileged group and a value > 0 implies higher benefit for the unprivileged group.\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aaQWChbDang",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "0129f8f6-28e2-4721-a8a7-6a5ea716c8aa"
      },
      "source": [
        "printb(\"Nondebiasing\")\n",
        "print(format_json(ex_nondebias_test.average_odds_difference()))\n",
        "\n",
        "printb(\"Debiasing\")\n",
        "print(format_json(ex_debias_test.average_odds_difference()))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30mNondebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Average Odds Difference\",\n",
            "  \"message\": \"Average odds difference (average of TPR difference and FPR difference, 0 = equality of odds): -0.30511296916822117\",\n",
            "  \"numFalsePositivesUnprivileged\": 0.0,\n",
            "  \"numNegativesUnprivileged\": 4326.0,\n",
            "  \"numTruePositivesUnprivileged\": 0.0,\n",
            "  \"numPositivesUnprivileged\": 531.0,\n",
            "  \"numFalsePositivesPrivileged\": 859.0,\n",
            "  \"numNegativesPrivileged\": 6853.0,\n",
            "  \"numTruePositivesPrivileged\": 1427.0,\n",
            "  \"numPositivesPrivileged\": 2943.0,\n",
            "  \"description\": \"Computed as average difference of false positive rate (false positives / negatives) and true positive rate (true positives / positives) between unprivileged and privileged groups.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 0.  A value of < 0 implies higher benefit for the privileged group and a value > 0 implies higher benefit for the unprivileged group.\"\n",
            "}\n",
            "\u001b[1;30mDebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Average Odds Difference\",\n",
            "  \"message\": \"Average odds difference (average of TPR difference and FPR difference, 0 = equality of odds): -0.03698233222265148\",\n",
            "  \"numFalsePositivesUnprivileged\": 381.0,\n",
            "  \"numNegativesUnprivileged\": 4326.0,\n",
            "  \"numTruePositivesUnprivileged\": 205.0,\n",
            "  \"numPositivesUnprivileged\": 531.0,\n",
            "  \"numFalsePositivesPrivileged\": 722.0,\n",
            "  \"numNegativesPrivileged\": 6853.0,\n",
            "  \"numTruePositivesPrivileged\": 1303.0,\n",
            "  \"numPositivesPrivileged\": 2943.0,\n",
            "  \"description\": \"Computed as average difference of false positive rate (false positives / negatives) and true positive rate (true positives / positives) between unprivileged and privileged groups.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 0.  A value of < 0 implies higher benefit for the privileged group and a value > 0 implies higher benefit for the unprivileged group.\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKeX3a5dKh4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "790debf3-cfaa-4479-97b9-b6826b196095"
      },
      "source": [
        "printb(\"Nondebiasing\")\n",
        "print(format_json(ex_nondebias_test.theil_index()))\n",
        "\n",
        "printb(\"Debiasing\")\n",
        "print(format_json(ex_debias_test.theil_index()))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30mNondebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Theil Index\",\n",
            "  \"message\": \"Theil index (generalized entropy index with alpha = 1): 0.1729900486204719\",\n",
            "  \"description\": \"Computed as the generalized entropy of benefit for all individuals in the dataset, with alpha = 1. It measures the inequality in benefit allocation for individuals.\",\n",
            "  \"ideal\": \"A value of 0 implies perfect fairness.\"\n",
            "}\n",
            "\u001b[1;30mDebiasing\u001b[0m\n",
            "{\n",
            "  \"metric\": \"Theil Index\",\n",
            "  \"message\": \"Theil index (generalized entropy index with alpha = 1): 0.17158484394822954\",\n",
            "  \"description\": \"Computed as the generalized entropy of benefit for all individuals in the dataset, with alpha = 1. It measures the inequality in benefit allocation for individuals.\",\n",
            "  \"ideal\": \"A value of 0 implies perfect fairness.\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrykTk1AVUH2",
        "colab_type": "text"
      },
      "source": [
        "# Excercises and questions\n",
        "\n",
        "Let's make sure you understand what you just did while working on this notebook.\n",
        "\n",
        "1. Rerun this notebook with `race` as the protected attribute. How different are the results on the fairness metrics?\n",
        "2. What does the `Adversarial Debiasing` technique do?\n",
        "3. What kind of classifier is this technique using? What hyperparameters could you tune?\n",
        "4. Can I use the current implementation to optimize for several protected attributes?\n"
      ]
    }
  ]
}
